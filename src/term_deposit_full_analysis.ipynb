{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac7adc-1eb1-442a-9d3e-baae198ab6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cfeeea-eeb7-46b4-bc62-6d50d3aaf8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank = pd.read_csv(\"../data/bank-full.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b016c-4a35-4eae-b9b5-b9b0cc3fb143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df_bank, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c4057-77cd-4980-ab8a-44661213a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57a2c7-f142-4ecd-a5dc-4618c0f45cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e310703-fc87-450f-a728-0597084147ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29405d93-4274-4173-84cb-c7cf47d8478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"y\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652ecdc-0613-4c64-9e9d-ecb60e76a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions of categorical and numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada49f7c-58dd-456a-b86a-bdd25c6c08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = list(train_df.drop(columns=[\"y\"]).select_dtypes(include=[\"object\"]).columns)\n",
    "numerical_cols = list(train_df.select_dtypes(include=[\"int64\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0421d0a-db05-4ab9-b24f-05cff7d333ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "\n",
    "alt.Chart(train_df).mark_bar().encode(\n",
    "    x=\"count()\",\n",
    "    y=alt.Y(alt.repeat()).type(\"nominal\")\n",
    ").repeat(\n",
    "    categorical_cols, columns=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae9e24-387a-445f-aa43-475fa1c485af",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(train_df).mark_bar().encode(\n",
    "    x=alt.X(alt.repeat()).type(\"quantitative\").bin(maxbins=40),\n",
    "    y=\"count()\"\n",
    ").repeat(\n",
    "    numerical_cols, columns=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca1d09-71fb-47d8-8876-c1c21bfa2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations between numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336175e8-115e-4a20-90cf-f63d71d4084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure linear relationship\n",
    "person_corr_df = train_df[numerical_cols].corr(\"pearson\").unstack().reset_index()\n",
    "person_corr_df.columns = [\"num_variable_0\", \"num_variable_1\", \"correlation\"]\n",
    "\n",
    "corr_heatmap = alt.Chart(person_corr_df).mark_rect().encode(\n",
    "    x=alt.X(\"num_variable_0\").title(\"Numerical Variable\"),\n",
    "    y=alt.Y(\"num_variable_1\").title(\"Numerical Variable\"),\n",
    "    color=\"correlation:Q\"\n",
    ").properties(\n",
    "    width=250,\n",
    "    height=250\n",
    ")\n",
    "\n",
    "text = alt.Chart(person_corr_df, title=\"Pearson Correlation\").mark_text().encode(\n",
    "    x=alt.X(\"num_variable_0\").title(\"Numerical Variable\"),\n",
    "    y=alt.Y(\"num_variable_1\").title(\"Numerical Variable\"),\n",
    "    text=alt.Text(\"correlation:Q\", format=\".2f\")\n",
    ")\n",
    "\n",
    "corr_heatmap + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b952e-e67f-4481-9234-82f2b9cd0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure monotonic (incl. non-linear) relationship\n",
    "spearman_corr_df = train_df[numerical_cols].corr(\"spearman\").unstack().reset_index()\n",
    "spearman_corr_df.columns = [\"num_variable_0\", \"num_variable_1\", \"correlation\"]\n",
    "\n",
    "corr_heatmap = alt.Chart(spearman_corr_df, title=\"Spearman Correlation\").mark_rect().encode(\n",
    "    x=alt.X(\"num_variable_0\").title(\"Numerical Variable\"),\n",
    "    y=alt.Y(\"num_variable_1\").title(\"Numerical Variable\"),\n",
    "    color=\"correlation:Q\"\n",
    ").properties(\n",
    "    width=250,\n",
    "    height=250\n",
    ")\n",
    "\n",
    "text = alt.Chart(spearman_corr_df).mark_text().encode(\n",
    "    x=alt.X(\"num_variable_0\").title(\"Numerical Variable\"),\n",
    "    y=alt.Y(\"num_variable_1\").title(\"Numerical Variable\"),\n",
    "    text=alt.Text(\"correlation:Q\", format=\".2f\")\n",
    ")\n",
    "\n",
    "corr_heatmap + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078ec77-0a66-47cd-9bfd-5c514ee74d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for correlation between pdays and previous\n",
    "# as indicated in the chart, there is no linear relationship here\n",
    "pdays_prev = alt.Chart(train_df, title=\"pdays vs previous\").mark_point().encode(\n",
    "    x=\"pdays\",\n",
    "    y=\"previous\"\n",
    ")\n",
    "\n",
    "pdays_prev_clamped = alt.Chart(train_df, title=\"pdays vs previous (previous <= 50)\").mark_point().encode(\n",
    "    x=\"pdays\",\n",
    "    y=alt.Y(\"previous\").scale(domain=(0, 50), clamp=True)\n",
    ")\n",
    "\n",
    "pdays_prev | pdays_prev_clamped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717a018-72e9-4e09-95d9-868fcddb90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data with its description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0afc1c-85f2-4ae9-a8b9-ddbd3daee752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# check all 31 days of the month exist\n",
    "np.sort(train_df[\"day\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca231b-bb9c-4a5e-8c03-073f82fd8ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that campaign >= 1; it is the number of contracts for this client during this campaign, including the last contract\n",
    "train_df[\"campaign\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce4cd3-cbc1-48b4-b080-63f009d8678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As indicated, all points > 0. (The red line indicates the minimum.)\n",
    "alt.Chart(train_df).mark_boxplot().encode(\n",
    "    alt.X(\"campaign\").scale(domain=(-5, 60), clamp=True)\n",
    ").properties(height=50) + alt.Chart(train_df).mark_rule().encode(x=\"min(campaign)\", color=alt.value(\"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3733a11-3fed-4ec2-be81-db8a5fd26577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that previous >= 0; it is the number of contracts for this client before this campaign\n",
    "train_df[\"previous\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9f9b5-1456-4ebd-a8b0-665666040ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As indicated, all points >= 0. (The red line indicates the minimum.)\n",
    "alt.Chart(train_df).mark_boxplot().encode(\n",
    "    alt.X(\"previous\").scale(domain=(-5, 50), clamp=True)\n",
    ").properties(height=50) + alt.Chart(train_df).mark_rule().encode(x=\"min(previous)\", color=alt.value(\"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d4845-5b3b-48c0-9c04-aab660f4692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that if previous = 0, then pdays = -1\n",
    "train_df.loc[train_df[\"previous\"] == 0, \"pdays\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3840e-31c3-4e80-a596-8fc305e780bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that if previous = 0, then outcome = \"unknown\"\n",
    "train_df.loc[train_df[\"previous\"] == 0, \"poutcome\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e0439-b7ac-438d-b922-9af48386a661",
   "metadata": {},
   "source": [
    "### Summary and Recommendations from EDA\n",
    "- Generally, bar charts were created for categorical variables, and histograms for numerical variables to show illustration. Correlation heatmaps based on two different metrics were generated to investigate the relationships between numerical variables. A scatter plot specifically for `pdays` vs `previous` was created.\n",
    "- Judging from the proportion of each class in the target, the dataset is unbalanced\n",
    "- `job`, `education`, `contact` and `poutcome` contain unknown values. We do not have enough information on the dataset to impute these values properly. Note that these values are not null values, but strings called \"unknown\". Out of these columns, `contact` and `poutcome` have significant numbers of \"unknown\" values.\n",
    "- `poutcome` is the outcome of the previous marketing campaign. Most of the \"unknown\" is because `previous = 0`. If the person has never been contacted for marketing before, it makes sense to say \"unknown\" for this field as \"previous marketing\" doesn't exist. But for those who have been reached out before, this `poutcome` might be informative! `contact` could be kept, because not that many \"unknown\" in it actually. Also, our task is to find out the importance of features. There should be no harm to keep it, but we would expect the result to tell me that this `contact` is not important.\n",
    "- The distributions of `pdays` and `previous` are heavily skewed. These variables are also correlated with 0.99 Spearman correlation score and 0.44 Pearson correlation score.\n",
    "- However, upon visual inspection with a scatter plot, `pdays` and `previous` do not seem to be too correlated to be an issue. We can keep them both as features.\n",
    "- Overall recommendations:\n",
    "   - Ordinal encode `education`\n",
    "   - One-hot encode categorical variables\n",
    "   - Standardize numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e132497-3e21-4e98-a8fc-96350ce7fa5d",
   "metadata": {},
   "source": [
    "### Discussion\n",
    " - In this study, we would like to understand which factors would affect the most for clients' subscription to the term deposit\n",
    " - positive label: `y = \"yes\"`; negative label: `y = \"no\"`\n",
    " - We do not want to miss any potential clients. Therefore, we would like to lower as much as possible the Type I error / false positive, i.e. clients being identified as subscribed to our term deposit but actually they didn't.\n",
    " - We will select a model that gives us a robust **precision**, so that the model could better explain clients' motivation to the subscription. We would put more trust to the feature importance recommended by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cb62e-9de9-4fe8-8cd0-e7298eaf6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns=[\"y\"]), train_df[\"y\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"y\"]), test_df[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc14744-068a-4981-acbc-2ba823d9be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "categorical_feats = [\"job\", \"marital\", \"default\", \"housing\", \"loan\", \"contact\", \"day\", \"month\", \"poutcome\"]\n",
    "ordinal_feats = [\"education\"]\n",
    "numeric_feats = [\"age\", \"balance\", \"duration\", \"campaign\", \"previous\", \"pdays\"]\n",
    "\n",
    "education_levels = [\"unknown\", \"primary\", \"secondary\", \"tertiary\"]\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(sparse_output=False, drop=\"if_binary\"), categorical_feats),\n",
    "    (OrdinalEncoder(categories=[education_levels], dtype=int), ordinal_feats),\n",
    "    (StandardScaler(), numeric_feats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addaedc-7da2-400a-b633-c8d340ac8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_pipes = {\n",
    "    \"Baseline\": DummyClassifier(strategy=\"most_frequent\", random_state=522),\n",
    "    \"DecisionTree\": make_pipeline(preprocessor, DecisionTreeClassifier(max_depth=5, random_state=522)),\n",
    "    \"LogisticRegression\": make_pipeline(preprocessor, LogisticRegression(max_iter=2000, random_state=522)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3ce3a-fa4e-426f-8bcc-551e49d51114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "mod_precision_score = make_scorer(precision_score, zero_division=0)\n",
    "\n",
    "classification_metrics = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": mod_precision_score,\n",
    "    \"recall\": \"recall\", \n",
    "}\n",
    "cross_val_results = {}\n",
    "\n",
    "for name, pipe in model_pipes.items():\n",
    "    cross_val_results[name] = pd.DataFrame(\n",
    "        cross_validate(\n",
    "            pipe, \n",
    "            X_train, \n",
    "            y_train==\"yes\", \n",
    "            cv=5,\n",
    "            return_train_score=True, \n",
    "            scoring=classification_metrics)\n",
    "    ).agg(['mean', 'std']).round(3).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092c04f-8a79-4877-b1cc-5ce117047e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    cross_val_results,\n",
    "    axis='columns'\n",
    ").xs(\n",
    "    'mean',\n",
    "    axis='columns',\n",
    "    level=1\n",
    ").style.format(\n",
    "    precision=2\n",
    ").background_gradient(\n",
    "    axis=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82c85e-e4f7-49cc-bd56-de385b1a023b",
   "metadata": {},
   "source": [
    "### Observation:\n",
    " - `LogisticRegression` has slightly better test precision than the `DecisionTreeClassifier`, but the `LogisticRegression` has a smaller gap between train scores and test scores, so `LogisticRegression` is more likely to generalize.\n",
    " - Limitation: there is still room of improvements on the precision\n",
    "   - In the future, if we ever need to make prediction of the subscription, we could increase the threshold to yield a better precision. So, I guess it's not so much worry here.\n",
    "   - If we really keen on improving the precision on the model level, we could see RandomForest is a choice, but not everyone of us know RandomForest yet, haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd9162-25fa-40e3-acbf-669d1ebd09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = model_pipes['LogisticRegression']\n",
    "\n",
    "lr_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54d186-e604-443f-ad37-5981d8aa9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, lr_pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b186e938-9219-42ec-932a-15f69277c9d3",
   "metadata": {},
   "source": [
    "### Observation\n",
    " - The precision test score is similar to the validation score as well as the train score. Therefore, we would believe that the feature importance conclusion drawn from this model is generalizable to the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857a682-ab5a-4bce-ace0-07f226e097e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = lr_pipe.named_steps['columntransformer'].named_transformers_['onehotencoder'].get_feature_names_out().tolist()\n",
    "ordinal_cols = lr_pipe.named_steps['columntransformer'].named_transformers_['ordinalencoder'].get_feature_names_out().tolist()\n",
    "numeric_cols = lr_pipe.named_steps['columntransformer'].named_transformers_['standardscaler'].get_feature_names_out().tolist()\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': categorical_cols + ordinal_cols + numeric_cols, \n",
    "    'coef': lr_pipe.named_steps['logisticregression'].coef_[0].tolist()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5495024-da78-444a-ac94-6e98125fbf4d",
   "metadata": {},
   "source": [
    "### Observation\n",
    " - According to the below dataframe, `poutcome`, `month` and `duration` are the top 3 features that are highly related to whether a client would subscribe to the term deposit or not.\n",
    "   - If `poutcome == \"success\"`, clients were already experiencing the good services by the bank, so they're more willing to subscribe new products.\n",
    "   - If `month == \"mar\"`, we are not sure why clients tend to accept the marketing and subscribe the term deposit in March, this pattern also exists in the test set, so it's not likely an over-fitting. We thought it might be related to the financial/tax period/bonus release time in Portugal, but it seems the finance year-end in Portugal is December (it could be March in some countries e.g. China). So we still can't make sense of it yet.\n",
    "   - If `duration` is longer, that means the clients were more interested in the term deposit product and were more likely to stay on the call, the salesperson had time to do more pitching, so increase the chance of successful subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554b8792-d342-4ec7-89f1-e3c68758e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.sort_values('coef', ascending=False).style.format(\n",
    "    precision=3\n",
    ").background_gradient(\n",
    "    cmap=\"PiYG\",\n",
    "    vmin=-2,\n",
    "    vmax=2,\n",
    "    axis=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07acd6f-b59c-48ed-b742-ce53537b2c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:522]",
   "language": "python",
   "name": "conda-env-522-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
